{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc5a97e-e804-4def-b998-bd69152d89dc",
   "metadata": {},
   "source": [
    "### Basically we need to convert the text into the format wich could be understand by the machine learning algorithms and deep learning algorithms ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1dc279-5a19-4993-889d-9db18f329c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fe21ea-d8cd-4d43-8c4d-3cd8b87bff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus='India, officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar and Indonesia.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1011abde-9484-4f89-859b-391da9725689",
   "metadata": {},
   "source": [
    "### 1. Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a58f6644-d786-48a7-a646-3dc076535804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Stopwords present: 51\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "for word in word_tokenize(corpus):\n",
    "    if(word.lower() not in stopwords.words('English')) and (len(word)>=2):\n",
    "        words.append(word.lower())\n",
    "\n",
    "# without stopwords    \n",
    "words_all=[]\n",
    "for word in word_tokenize(corpus):\n",
    "    if (len(word) == 1):\n",
    "        if ((ord(word) >= 97 and ord(word) <= 122) or (ord(word) >= 65 and ord(word) <= 90)):\n",
    "            words_all.append(word.lower())\n",
    "    else:\n",
    "        words_all.append(word.lower())\n",
    "\n",
    "print('Total Stopwords present:',abs(len(words_all)-len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2fe789-eccc-4353-9185-4c60585a85ac",
   "metadata": {},
   "source": [
    "### 2. Creating Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eea35c38-8c5f-4f56-b654-655ba69841fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "45\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "vocab=list(set(words))\n",
    "print(len(vocab))\n",
    "vocab_all= list(set(words_all))\n",
    "print(len(vocab_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d98bd-8267-4179-9eb2-2c7fbffbdcc0",
   "metadata": {},
   "source": [
    "### 3. Creating Encoders and Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4e8309c-fab7-494a-9774-e34fa7f23a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "num=1\n",
    "word_to_num={}\n",
    "num_to_word={}\n",
    "\n",
    "for word in vocab:\n",
    "    word_to_num[word]=num\n",
    "    num_to_word[num]=word\n",
    "    num+=1\n",
    "\n",
    "print(word_to_num['india'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ed0dd-c6e2-4d53-8b03-f1631fe66698",
   "metadata": {},
   "source": [
    "### 4. Encoding Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc0ceb52-c0df-4e1e-9ae5-6ae2fb006ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 13, 38, 40, 28, 31, 43]\n",
      "[20, 28, 30, 35, 15, 28, 15, 26, 45]\n",
      "[19, 16, 9, 31, 42, 27, 33, 22, 1, 34, 3, 2, 25, 44, 17, 32, 37, 29, 24, 4, 6, 23]\n",
      "[16, 9, 40, 5, 41, 11, 8, 7, 18, 39, 21, 36, 12, 14, 6, 10]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for sent in sent_tokenize(corpus):\n",
    "    temp = []\n",
    "    for word in word_tokenize(sent):\n",
    "        if (word.lower() not in stopwords.words('english') and (len(word) >= 2)):\n",
    "          #print(word, end = ' ')\n",
    "            temp.append(word_to_num[word.lower()])\n",
    "    # print()            \n",
    "    print(temp)\n",
    "    \n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84ca66-55b6-4be5-a11e-de5aac775ab9",
   "metadata": {},
   "source": [
    "### 5.Decoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93ed41f5-8f5e-4105-ba6c-0267264fe6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india officially republic india country south asia \n",
      "seventh-largest country area second-most populous country populous democracy world \n",
      "bounded indian ocean south arabian sea southwest bay bengal southeast shares land borders pakistan west china nepal bhutan north bangladesh myanmar east \n",
      "indian ocean india vicinity sri lanka maldives andaman nicobar islands share maritime border thailand myanmar indonesia \n"
     ]
    }
   ],
   "source": [
    "for sent in data:\n",
    "    for word in sent:\n",
    "        print(num_to_word[word], end = ' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81cd9cb8-4478-45ec-b675-9f4a437d0144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "islands\n",
      "arabian\n",
      "bhutan\n",
      "officially\n",
      "second-most\n",
      "bhutan\n",
      "west\n"
     ]
    }
   ],
   "source": [
    "for i in [39,42,29,13,35,29,17]:\n",
    "    print(num_to_word[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e37cb33-1d96-4f02-9881-91cbbbfb9f3a",
   "metadata": {},
   "source": [
    "## One Hot Encoding.\n",
    "This technique is used for encoding the wordsin some sort of numbers, including the sentences into the numerical data in sort to perform some mathemarical operations or computations on it ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc43b95-429c-45c9-82d8-9d1bcfca03ab",
   "metadata": {},
   "source": [
    "<b>Process:</b> we first need to find the number of uniquq words in it and then define the sequncen of the words which remains cnostan throughout then arrange the zero and one as per the words in prsent in th esentences accorsing to the sequnce defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889a27d-43d3-4e4a-8297-4516a8abd783",
   "metadata": {},
   "source": [
    "The lenght of the sequnce deifned is hte number of the unique words present in the corpus and each sentence needs to coded in that length only whih is fixed (could it be a flaw).\n",
    "\n",
    " ['all','at', 'bad', 'not','its'] <br>\r\n",
    "'its not bad at all' [1 , 1 , 1 , 1 , 1] 'its not bad' [0 , 0 , 1 , 1 , 1] 'its bad' [0 , 0 , 1 , 0 , 1] 'not bad at all' [1 , 1 , 1 , 1 , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25fbeb30-7d9e-4f3f-bf9f-696eb978ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "corpus = 'GeeksforGeeks is not a website or a company. GeeksforGeeks is a coding environment. Thats what i love. Which is good. Not bad at all'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec5064b-4717-4883-b0a4-2509ee153609",
   "metadata": {},
   "source": [
    "### 1. Finding the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70df3b38-59d4-404f-a712-591b926fc97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'Thats', 'bad', 'all', 'is', 'Which', 'company', 'Not', 'not', 'GeeksforGeeks', 'a', 'at', 'good', 'website', 'what', 'environment', 'i', 'coding', 'or']\n"
     ]
    }
   ],
   "source": [
    "seq = set()\n",
    "\n",
    "for word in word_tokenize(corpus):\n",
    "    if(word != '.'):\n",
    "        seq.add(word)\n",
    "        \n",
    "seq = list(seq)\n",
    "\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06fa905-9579-4212-8481-e449e756fe3d",
   "metadata": {},
   "source": [
    "### 2. Finding Index to Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebf292e3-4f44-4fe5-9726-04655edd7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for sent in sent_tokenize(corpus):\n",
    "    index = []\n",
    "    for word in word_tokenize(sent):\n",
    "        if(word != '.'):\n",
    "            index.append(seq.index(word))\n",
    "            \n",
    "    data.append(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe1ca7-9f5c-4143-a687-e0d2667b5245",
   "metadata": {},
   "source": [
    "### 3. Encode the Sentances in One Hot Encoding Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca758bb6-5151-45d1-be64-86e0c587c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = []\n",
    "\n",
    "for indexes in data:\n",
    "    enc = [0 for x in range(len(seq))]\n",
    "    for index in indexes:\n",
    "        enc[index] = 1\n",
    "    fin.append(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f33f4-cfc9-4507-9a45-859c4f20081b",
   "metadata": {},
   "source": [
    "### 4.Creating the DataFrame / Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "466bbf28-ee5e-46d9-883b-d8a4e48ae4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>love</th>\n",
       "      <th>Thats</th>\n",
       "      <th>bad</th>\n",
       "      <th>all</th>\n",
       "      <th>is</th>\n",
       "      <th>Which</th>\n",
       "      <th>company</th>\n",
       "      <th>Not</th>\n",
       "      <th>not</th>\n",
       "      <th>GeeksforGeeks</th>\n",
       "      <th>a</th>\n",
       "      <th>at</th>\n",
       "      <th>good</th>\n",
       "      <th>website</th>\n",
       "      <th>what</th>\n",
       "      <th>environment</th>\n",
       "      <th>i</th>\n",
       "      <th>coding</th>\n",
       "      <th>or</th>\n",
       "      <th>Sentances_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GeeksforGeeks is not a website or a company.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GeeksforGeeks is a coding environment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thats what i love.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Which is good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not bad at all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   love  Thats  bad  all  is  Which  company  Not  not  GeeksforGeeks  a  at  \\\n",
       "0     0      0    0    0   1      0        1    0    1              1  1   0   \n",
       "1     0      0    0    0   1      0        0    0    0              1  1   0   \n",
       "2     1      1    0    0   0      0        0    0    0              0  0   0   \n",
       "3     0      0    0    0   1      1        0    0    0              0  0   0   \n",
       "4     0      0    1    1   0      0        0    1    0              0  0   1   \n",
       "\n",
       "   good  website  what  environment  i  coding  or  \\\n",
       "0     0        1     0            0  0       0   1   \n",
       "1     0        0     0            1  0       1   0   \n",
       "2     0        0     1            0  1       0   0   \n",
       "3     1        0     0            0  0       0   0   \n",
       "4     0        0     0            0  0       0   0   \n",
       "\n",
       "                                     Sentances_  \n",
       "0  GeeksforGeeks is not a website or a company.  \n",
       "1        GeeksforGeeks is a coding environment.  \n",
       "2                            Thats what i love.  \n",
       "3                                Which is good.  \n",
       "4                                Not bad at all  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(fin, columns = seq)\n",
    "df['Sentances_'] = sent_tokenize(corpus)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d2d50be-46da-4276-abe7-ae2bd6a36c40",
   "metadata": {},
   "source": [
    "                        ['This','is','not','bad','good','at','all']\n",
    "\n",
    "'This is good, not bad at all'      [1,1,1,1,1,1]\n",
    "'This is bad, not good at all'      [1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724a7d7-4ca4-4a81-b4a5-8b5ecd9d8165",
   "metadata": {},
   "source": [
    "NOTE: Flaws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a3621c-976d-477b-bc86-429a274c8e02",
   "metadata": {},
   "source": [
    "### using prebuild model from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a4b58-d6e8-4cd8-affa-3a8447bc7060",
   "metadata": {},
   "source": [
    "### 1. Adding one word at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c4fa79-a4bf-4f19-b634-9f2e0b694c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       a      b      c      d      e\n",
      "0   True  False  False  False  False\n",
      "1  False   True  False  False  False\n",
      "2  False  False   True  False  False\n",
      "3  False  False  False   True  False\n",
      "4  False  False  False  False   True\n",
      "5  False  False   True  False  False\n",
      "6  False   True  False  False  False\n",
      "----------------\n",
      "Index(['a', 'b', 'c', 'd', 'e'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "text=['a','b','c','d','e','c','b']\n",
    "data= pd.get_dummies(text)\n",
    "print(data)\n",
    "print('--'*8)\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc6f87-e801-4748-b464-7d96cc757790",
   "metadata": {},
   "source": [
    "### 2. Whole sentence at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5331ae4-eae5-443a-b80c-1f6ed293dee7",
   "metadata": {},
   "source": [
    "we will use the one hot encoder from sklearn where encoder input is (1,1) shaped . so we will first reshape the daat to that from and further use the pre-built one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "686447bc-3627-497e-8f28-0fabb58accbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OneHotEncoder' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m one_hot \u001b[38;5;241m=\u001b[39m encoder_\u001b[38;5;241m.\u001b[39mtransform(text)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(one_hot\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m([i[\u001b[38;5;241m3\u001b[39m:]\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m encoder_\u001b[38;5;241m.\u001b[39mget_feature_names()])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "text = ['i love dogs', 'i hate cats', 'i like turtles', 'i love the dogs']\n",
    "text= np.reshape(text,(-1,1))\n",
    "\n",
    "encoder_=OneHotEncoder()\n",
    "encoder_.fit(text)\n",
    "\n",
    "one_hot = encoder_.transform(text)\n",
    "\n",
    "print(one_hot.toarray())\n",
    "print([i[3:]for i in encoder_.get_feature_names()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f3e5a0-13db-4679-90d6-1f2431ea06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "['x0_i hate cats' 'x0_i like turtles' 'x0_i love dogs'\n",
      " 'x0_i love the dogs']\n",
      "['i hate cats', 'i like turtles', 'i love dogs', 'i love the dogs']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "text = ['i love dogs', 'i hate cats', 'i like turtles', 'i love the dogs']\n",
    "\n",
    "text = np.reshape(text, (-1, 1))\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(text)\n",
    "\n",
    "one_hot = encoder.transform(text)\n",
    "\n",
    "print(one_hot.toarray())\n",
    "print(encoder_.get_feature_names_out())\n",
    "print([i[3:]for i in encoder.get_feature_names_out()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bbf56-6f0c-4ba2-808d-c7f82b8d5f8c",
   "metadata": {},
   "source": [
    "### 3. Tokenized Sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e3c9c79-41ea-4af4-8bc6-26a0ee391c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[0. 1. 1. 0. 0. 1.]\n",
      " [1. 0. 0. 1. 1. 0.]]\n",
      "----------------\n",
      "<generator object <genexpr> at 0x0000024C16AEBCA0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = [['this' ,'is' ,'good'], ['but','its','fine']]\n",
    "\n",
    "print(np.shape(text))\n",
    "\n",
    "## its fot the format of(-1,1)\n",
    "## so we need to process directly \n",
    "encoder=OneHotEncoder()\n",
    "one_hot=encoder.fit_transform(text)\n",
    "\n",
    "print(one_hot.toarray())\n",
    "print('--'*8)\n",
    "print(i[3:] for i in encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d4076b-a0cf-4650-a63a-6541d5c5aa69",
   "metadata": {},
   "source": [
    "#### To dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbba47d5-64a1-4d7f-93ff-7af99f1ba699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>but</th>\n",
       "      <th>this</th>\n",
       "      <th>is</th>\n",
       "      <th>its</th>\n",
       "      <th>fine</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   but  this   is  its  fine  good\n",
       "0  0.0   1.0  1.0  0.0   0.0   1.0\n",
       "1  1.0   0.0  0.0  1.0   1.0   0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame(one_hot.toarray(),columns= [i[3:] for i in encoder.get_feature_names_out()])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68141cc8-2ff6-4de4-8c89-d4d325e5044a",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0858d17-46b4-4830-8840-822293a9c27f",
   "metadata": {},
   "source": [
    "Bag of Words (BoW) is a simple and widely used text representation technique. It is used to convert text data (such as sentences) into numerical format, which can then be fed into machine learning algorithms. The key idea behind BoW is to represent text as a collection (or \"bag\") of words, without considering grammar or word order but keeping track of word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccec4844-a31f-49ec-99fc-84516f2986b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>cute</th>\n",
       "      <th>is</th>\n",
       "      <th>The</th>\n",
       "      <th>very</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The is a very very cute cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The dog is very cute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  cat  dog  cute  is  The  very                     Sentence\n",
       "0  1    1    0     1   1    1     2  The is a very very cute cat\n",
       "1  0    0    1     1   1    1     1         The dog is very cute"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feature_names=[]\n",
    "word_text = [\"The is a very very cute cat\", \"The dog is very cute\"]\n",
    "\n",
    "tokens=[token .split() for token in word_text]\n",
    "vocab=list(set([word for text in tokens for word in text]))\n",
    "\n",
    "for text in tokens:\n",
    "    temp_vector=[0]*len(vocab)\n",
    "    for word in text:\n",
    "        temp_vector[vocab.index(word)]=text.count(word)\n",
    "    feature_names.append(temp_vector)\n",
    "\n",
    "df=pd.DataFrame(feature_names,columns=vocab)\n",
    "df['Sentence']=word_text\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33042c-a748-4bee-8b98-d11b9f821723",
   "metadata": {},
   "source": [
    "### Binary Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a12268b3-9f74-4ad7-a346-c2fff859f5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>cute</th>\n",
       "      <th>is</th>\n",
       "      <th>The</th>\n",
       "      <th>very</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The is a very very cute cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The dog is very cute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  cat  dog  cute  is  The  very                     Sentence\n",
       "0  1    1    0     1   1    1     1  The is a very very cute cat\n",
       "1  0    0    1     1   1    1     1         The dog is very cute"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_vectors = []\n",
    "\n",
    "word_text = [\"The is a very very cute cat\", \"The dog is very cute\"]  \n",
    "\n",
    "tokens=[token.split() for token in word_text]\n",
    "\n",
    "vocab = list(set([word for text in tokens for word in text]))\n",
    "\n",
    "for text in tokens:\n",
    "    temp_vector=[0]*len(vocab)\n",
    "    for word in text:\n",
    "        if word in vocab:\n",
    "            temp_vector[vocab.index(word)]=1\n",
    "    feature_vectors.append(temp_vector)\n",
    "\n",
    "df_1 = pd.DataFrame(feature_vectors , columns=vocab)\n",
    "df_1['Sentence']=word_text\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2605df0-c7b0-4985-b557-7dbcbbf2be38",
   "metadata": {},
   "source": [
    "##  Count Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf6bc4-2f2c-4fb3-85d2-5f9bd2901fe2",
   "metadata": {},
   "source": [
    "### 1. Fitting and Transform seprately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da0ef7a1-6ac4-4f7d-ac3e-90e66398ef51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gfg</th>\n",
       "      <th>is</th>\n",
       "      <th>providing</th>\n",
       "      <th>new</th>\n",
       "      <th>deep</th>\n",
       "      <th>learning</th>\n",
       "      <th>course</th>\n",
       "      <th>which</th>\n",
       "      <th>really</th>\n",
       "      <th>good</th>\n",
       "      <th>we</th>\n",
       "      <th>will</th>\n",
       "      <th>be</th>\n",
       "      <th>studying</th>\n",
       "      <th>from</th>\n",
       "      <th>today</th>\n",
       "      <th>want</th>\n",
       "      <th>sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gfg  is  providing  new  deep  learning  course  which  really  good  we  \\\n",
       "0    0   1          1    0     1         1       2      1       1     1   1   \n",
       "1    1   0          1    1     0         0       0      1       0     0   0   \n",
       "2    0   0          1    0     0         0       0      0       0     0   0   \n",
       "\n",
       "   will  be  studying  from  today  want  sleep  \n",
       "0     0   0         0     0      0     1      0  \n",
       "1     0   1         1     0      1     0      1  \n",
       "2     1   0         1     1      0     0      0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pandas import DataFrame\n",
    "\n",
    "text_data  = [ \"GFG is providing a new Deep Learning Course which is really good\",\n",
    "               \"We will be studying Deep Learning from today\",\n",
    "               \"I want a Deep sleep today\"]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "vec = vec.fit(text_data)\n",
    "\n",
    "data_transformed = vec.transform(text_data)\n",
    "\n",
    "df = DataFrame(data_transformed.toarray(), columns = vec.vocabulary_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2b28e-57d6-4e56-b6bc-5c4f859acbbf",
   "metadata": {},
   "source": [
    "### 2. Dealing with various properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dbff129-e85d-4f7f-a95d-a4f0e764399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gfg</th>\n",
       "      <th>providing</th>\n",
       "      <th>new</th>\n",
       "      <th>deep</th>\n",
       "      <th>learning</th>\n",
       "      <th>course</th>\n",
       "      <th>really</th>\n",
       "      <th>good</th>\n",
       "      <th>studying</th>\n",
       "      <th>today</th>\n",
       "      <th>want</th>\n",
       "      <th>sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gfg  providing  new  deep  learning  course  really  good  studying  today  \\\n",
       "0    1          1    1     1         1       1       1     1         0      0   \n",
       "1    0          1    0     0         1       0       0     0         0      1   \n",
       "2    0          1    0     0         0       0       0     0         1      0   \n",
       "\n",
       "   want  sleep  \n",
       "0     0      0  \n",
       "1     1      0  \n",
       "2     1      1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec=CountVectorizer( ngram_range=(1, 1), stop_words=('english'),   lowercase=True)\n",
    "vec=vec.fit(text_data)\n",
    "transformed=vec.transform(text_data)\n",
    "df= DataFrame(transformed.toarray(),columns= vec.vocabulary_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa70cf28-5dd5-49dd-8206-847b2c992fd6",
   "metadata": {},
   "source": [
    "### 3. Chracter level Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87021761-3ed7-42f9-847f-b26effd16bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g</th>\n",
       "      <th>f</th>\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>o</th>\n",
       "      <th>v</th>\n",
       "      <th>d</th>\n",
       "      <th>...</th>\n",
       "      <th>e</th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>c</th>\n",
       "      <th>u</th>\n",
       "      <th>h</th>\n",
       "      <th>y</th>\n",
       "      <th>b</th>\n",
       "      <th>t</th>\n",
       "      <th>m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    g  f     i  s  p  r  o  v  d  ...  e  w  l  c  u  h  y  b  t  m\n",
       "0  11  3  0  2  3  6  1  5  2  6  ...  4  4  2  4  3  0  1  1  2  1\n",
       "1   7  2  1  0  3  5  1  2  0  3  ...  3  2  1  2  1  2  1  0  2  2\n",
       "2   5  3  0  0  2  4  0  0  0  1  ...  1  1  2  0  1  2  0  0  1  1\n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec=CountVectorizer( ngram_range=(1, 1),lowercase=True,analyzer='char')\n",
    "vec=vec.fit(text_data)\n",
    "transformed=vec.transform(text_data)\n",
    "df= DataFrame(transformed.toarray(),columns= vec.vocabulary_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee64e1-84ba-4d72-a190-966fe981cee2",
   "metadata": {},
   "source": [
    "#### From Scratch building (chracter level encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9aac2eb-52b0-41a7-b875-9075708dc514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[[3, 12, 14, 5, 4, 14, 5, 4, 0, 4, 5, 0, 10, 11, 9, 1, 4, 5, 1, 13, 6, 1, 13, 17, 1], [2, 13, 8, 6, 12, 1, 15, 4, 1, 16, 0, 10, 11, 9, 1, 4, 5, 1, 13, 6, 1, 13, 17, 1], [7, 13, 1, 4, 10, 8, 15, 1, 4, 6, 1, 16, 6, 4, 5, 1, 13, 6, 1, 13, 17, 1], [6, 12, 14, 5]]\n"
     ]
    }
   ],
   "source": [
    "text_data = [\"This is a sample sentence\", \"Another example sentence\", \"One more text sentence\",'this']\n",
    "\n",
    "characters = list(set(''.join(text_data)))\n",
    "print(len(characters))\n",
    "\n",
    "chr_to_int = {i : indx  for indx , i in enumerate(characters)}\n",
    "\n",
    "enc_data = [[chr_to_int[char] for char in sent] for sent in text_data]\n",
    "print(enc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b3e3c-7495-4e9d-819a-3b2753eebb08",
   "metadata": {},
   "source": [
    "#### From Scratch Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35ca3705-f9f7-4fe9-992a-2bb68d38b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a sample sentence', 'Another example sentence', 'One more text sentence', 'this']\n"
     ]
    }
   ],
   "source": [
    "int_to_chr = {indx : i  for indx , i in enumerate(characters)}\n",
    "\n",
    "dec_data = [''.join([int_to_chr[char] for char in sent]) for sent in end_data]\n",
    "print(dec_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb00db-9496-4ed4-bee1-8a42cea86514",
   "metadata": {},
   "source": [
    "## TF_IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810f11f-1451-4746-b77e-ec2bf14c5b89",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency - Inverse Document Frequency) is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents (corpus). It‚Äôs commonly used in text mining and information retrieval.\n",
    "\n",
    "Here's how TF-IDF works:\n",
    "\n",
    "Term Frequency (TF): This measures how frequently a term (word) appears in a document.<br>\n",
    "\n",
    "TF(ùë°,ùëë)=Number¬†of¬†times¬†term¬†ùë° appears¬†in¬†document¬†ùëë / Total¬†number¬†of¬†terms¬†in¬†document¬† ùëë <br>\n",
    "\n",
    "Inverse Document Frequency (IDF): This measures the importance of the term in the entire corpus. It helps to down-weight terms that appear very frequently across documents (e.g., common words like \"the\" or \"and\").\n",
    "<br>\n",
    "IDF(ùë°,ùê∑)=log(\n",
    "Total¬†number¬†of¬†documents¬†in¬†corpus¬†ùê∑/\n",
    "Number¬†of¬†documents¬†containing¬†term¬†ùë°\n",
    ")\n",
    "<br>\n",
    "TF-IDF: The final value is the product of TF and IDF:\n",
    "\n",
    "TF-IDF(t,d,D)=TF(t,d)√óIDF(t,D)\n",
    "\n",
    "This score indicates the importance of a term in a specific document relative to the entire corpus.\n",
    "\n",
    "Example\n",
    "Suppose you have a corpus with three documents:<br>\n",
    "\n",
    "Doc 1: \"Deep learning is powerful.\"<br>\n",
    "Doc 2: \"Machine learning is a subset of AI.\"<br>\n",
    "Doc 3: \"AI is the future of technology.\"<br>\n",
    "Let‚Äôs calculate the TF-IDF for the term ‚Äúlearning‚Äù in the first document:<br>\n",
    "\n",
    "TF for \"learning\" in Doc 1 = 1/4 (because \"learning\" appears once in a total of 4 words).<br>\n",
    "IDF for \"learning\" = log(3/2) (since \"learning\" appears in 2 out of the 3 documents).<br>\n",
    "TF-IDF for \"learning\" in Doc 1 = (1/4) * log(3/2).<br>\n",
    "This process is repeated for each term in each document, resulting in a vector of TF-IDF values for the document.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c437e9a5-719a-4666-a9b2-826293017438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>movie</th>\n",
       "      <th>bad</th>\n",
       "      <th>full_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>good movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202733</td>\n",
       "      <td>bad movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135155</td>\n",
       "      <td>good bad movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       good  movie       bad       full_sent\n",
       "0  0.202733    0.0  0.000000      good movie\n",
       "1  0.000000    0.0  0.202733       bad movie\n",
       "2  0.135155    0.0  0.135155  good bad movie"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "text_data=[\"good movie\", \"bad movie\", \"good bad movie\"]\n",
    "\n",
    "# Sentences and Word Tokenization\n",
    "word_data = [sentence.split(' ') for sentence in text_data]\n",
    "# print(word_data)\n",
    "# Finding the Vocab\n",
    "vocab = list(set([word for sentence in word_data for word in sentence]))\n",
    "# print(vocab)\n",
    "\n",
    "# Finding Term Frequency\n",
    "tf_data = []\n",
    "for sentence in word_data:\n",
    "    tf_sentence = []\n",
    "    for word in vocab:\n",
    "        tf_sentence.append(sentence.count(word)/len(sentence))\n",
    "    tf_data.append(tf_sentence)\n",
    "\n",
    "# print(tf_data)\n",
    "\n",
    "n_documents = len(text_data)\n",
    "idf_data = []\n",
    "for word in vocab:  \n",
    "    n_appearances = 0\n",
    "    for sentence in word_data:\n",
    "        if word in sentence:\n",
    "            n_appearances += 1\n",
    "\n",
    "    idf = np.log(n_documents/n_appearances)\n",
    "    idf_data.append(idf)  \n",
    "# print(idf_data)\n",
    "\n",
    "# Finding TF-IDF for each sentence\n",
    "tfidf_data = []\n",
    "for tf_sentence in tf_data:\n",
    "    tfidf_sentence = []\n",
    "    for tf, idf in zip(tf_sentence, idf_data):\n",
    "        tfidf_sentence.append(tf*idf)\n",
    "    tfidf_data.append(tfidf_sentence)\n",
    "    \n",
    "df = pd.DataFrame(tfidf_data, columns = vocab)\n",
    "df['full_sent'] = text_data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9376b-380a-47a3-9222-e9d8f8c22418",
   "metadata": {},
   "source": [
    "   ### With sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de18be17-2653-4be0-85ca-c7ef21f99e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>movie</th>\n",
       "      <th>bad</th>\n",
       "      <th>full_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>good movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202733</td>\n",
       "      <td>bad movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135155</td>\n",
       "      <td>good bad movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       good  movie       bad       full_sent\n",
       "0  0.202733    0.0  0.000000      good movie\n",
       "1  0.000000    0.0  0.202733       bad movie\n",
       "2  0.135155    0.0  0.135155  good bad movie"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding TF-IDF for each sentence\n",
    "tfidf_data = []\n",
    "for tf_sentence in tf_data:\n",
    "    tfidf_sentence = []\n",
    "    for tf, idf in zip(tf_sentence, idf_data):\n",
    "        tfidf_sentence.append(tf*idf)\n",
    "    tfidf_data.append(tfidf_sentence)\n",
    "    \n",
    "df = pd.DataFrame(tfidf_data, columns = vocab)\n",
    "df['full_sent'] = text_data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea50b3b3-e177-4299-bf03-07b7e14b0fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'l', 'm', 'n',\n",
       "       'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb7327-2b0f-4460-980f-ace340563775",
   "metadata": {},
   "source": [
    "### TF_IDF on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "864ee23e-33e3-40f3-b941-652928723d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\deeps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\deeps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e6bcd-9310-4818-931b-e6cb83142396",
   "metadata": {},
   "source": [
    "### Import The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "badede37-5412-4c1a-9711-006c64ebf4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_validation.csv', header = None)\n",
    "df = df.rename({0 : 'id', 1 : 'company', 2 : 'sentiment', 3 : 'raw_tweet'}, axis = 1)\n",
    "\n",
    "df = df[df['sentiment'] != 'Irrelevant']\n",
    "df = df[df['sentiment'] != 'Neutral']\n",
    "\n",
    "tweets = df['raw_tweet'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c766a606-f087-421a-8b36-88257d63f70e",
   "metadata": {},
   "source": [
    "### Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65f7907b-ead2-4cc3-b1ad-dcf583e42d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    \n",
    "    tweet = re.sub(r'[^a-zA-Z]',' ',tweet)    \n",
    "    tweet = tweet.lower()\n",
    "    tweet = [word for word in tweet.split(' ') if not word in stopwords.words('english')]\n",
    "    tweet = [stemmer.stem(word) for word in tweet]\n",
    "    tweet = [word for word in tweet if len(word) != 0]\n",
    "    tweet = ' '.join(tweet)\n",
    "\n",
    "    processed_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12668ee3-9164-48a2-adb0-224285239948",
   "metadata": {},
   "source": [
    "### TF_IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f004e5a-3db9-419b-8ddf-514dadedaa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absurd</th>\n",
       "      <th>access</th>\n",
       "      <th>accessibleatx</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>account</th>\n",
       "      <th>aceofpyrit</th>\n",
       "      <th>achiev</th>\n",
       "      <th>...</th>\n",
       "      <th>ziryhrf</th>\n",
       "      <th>zlcc</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zqw</th>\n",
       "      <th>ztc</th>\n",
       "      <th>ztl</th>\n",
       "      <th>zukf</th>\n",
       "      <th>zy</th>\n",
       "      <th>zyot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows √ó 2499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abil  abl  absolut  absurd  access  accessibleatx  accomplish   account  \\\n",
       "0     0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "1     0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "2     0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.193864   \n",
       "3     0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "4     0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "..    ...  ...      ...     ...     ...            ...         ...       ...   \n",
       "538   0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "539   0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "540   0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "541   0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "542   0.0  0.0      0.0     0.0     0.0            0.0         0.0  0.000000   \n",
       "\n",
       "     aceofpyrit  achiev  ...  ziryhrf  zlcc  zone  zoom  zqw  ztc  ztl  zukf  \\\n",
       "0           0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "1           0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "2           0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "3           0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "4           0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "..          ...     ...  ...      ...   ...   ...   ...  ...  ...  ...   ...   \n",
       "538         0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "539         0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "540         0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "541         0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "542         0.0     0.0  ...      0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0   \n",
       "\n",
       "      zy  zyot  \n",
       "0    0.0   0.0  \n",
       "1    0.0   0.0  \n",
       "2    0.0   0.0  \n",
       "3    0.0   0.0  \n",
       "4    0.0   0.0  \n",
       "..   ...   ...  \n",
       "538  0.0   0.0  \n",
       "539  0.0   0.0  \n",
       "540  0.0   0.0  \n",
       "541  0.0   0.0  \n",
       "542  0.0   0.0  \n",
       "\n",
       "[543 rows x 2499 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "enc_tweets = tfidf.fit_transform(processed_tweets)\n",
    "\n",
    "df_ = pd.DataFrame(enc_tweets.toarray(), columns = tfidf.get_feature_names_out())\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42827c4f-8135-4dfa-933b-ed7c0fdf97e7",
   "metadata": {},
   "source": [
    "### Saving the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca4bd287-a07c-4424-9beb-bf8453d35e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is saved with name tfidf_model.joblib!\n",
      "Encodings are saved with name tfidf_enc.csv\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(tfidf, 'tfidf_model.joblib')\n",
    "\n",
    "df.to_csv('tfidf_enc.csv', index = False)\n",
    "\n",
    "print('Model is saved with name tfidf_model.joblib!')\n",
    "print('Encodings are saved with name tfidf_enc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "478c0857-1352-42aa-83a0-dea0704d7f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load('tfidf_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37bb5a-cf51-4665-b556-eff218752ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
